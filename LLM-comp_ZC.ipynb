{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfea09b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cemzuza\\Desktop\\llm-classification-finetuning\\train.csv ==> True\n",
      "C:\\Users\\cemzuza\\Desktop\\llm-classification-finetuning\\test.csv ==> True\n",
      "C:\\Users\\cemzuza\\Desktop\\llm-classification-finetuning\\sample_submission.csv ==> True\n",
      "Train shape: (57477, 9)\n",
      "Test shape : (3, 4)\n",
      "\n",
      "Kolumny train: ['id', 'model_a', 'model_b', 'prompt', 'response_a', 'response_b', 'winner_model_a', 'winner_model_b', 'winner_tie']\n",
      "Kolumny test : ['id', 'prompt', 'response_a', 'response_b']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>model_a</th>\n",
       "      <th>model_b</th>\n",
       "      <th>prompt</th>\n",
       "      <th>response_a</th>\n",
       "      <th>response_b</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30192</td>\n",
       "      <td>gpt-4-1106-preview</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"Is it morally right to try to have a certain...</td>\n",
       "      <td>[\"The question of whether it is morally right ...</td>\n",
       "      <td>[\"As an AI, I don't have personal beliefs or o...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53567</td>\n",
       "      <td>koala-13b</td>\n",
       "      <td>gpt-4-0613</td>\n",
       "      <td>[\"What is the difference between marriage lice...</td>\n",
       "      <td>[\"A marriage license is a legal document that ...</td>\n",
       "      <td>[\"A marriage license and a marriage certificat...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65089</td>\n",
       "      <td>gpt-3.5-turbo-0613</td>\n",
       "      <td>mistral-medium</td>\n",
       "      <td>[\"explain function calling. how would you call...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>[\"Function calling is the process of invoking ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id             model_a         model_b  \\\n",
       "0  30192  gpt-4-1106-preview      gpt-4-0613   \n",
       "1  53567           koala-13b      gpt-4-0613   \n",
       "2  65089  gpt-3.5-turbo-0613  mistral-medium   \n",
       "\n",
       "                                              prompt  \\\n",
       "0  [\"Is it morally right to try to have a certain...   \n",
       "1  [\"What is the difference between marriage lice...   \n",
       "2  [\"explain function calling. how would you call...   \n",
       "\n",
       "                                          response_a  \\\n",
       "0  [\"The question of whether it is morally right ...   \n",
       "1  [\"A marriage license is a legal document that ...   \n",
       "2  [\"Function calling is the process of invoking ...   \n",
       "\n",
       "                                          response_b  winner_model_a  \\\n",
       "0  [\"As an AI, I don't have personal beliefs or o...               1   \n",
       "1  [\"A marriage license and a marriage certificat...               0   \n",
       "2  [\"Function calling is the process of invoking ...               0   \n",
       "\n",
       "   winner_model_b  winner_tie  \n",
       "0               0           0  \n",
       "1               1           0  \n",
       "2               0           1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = Path(r\"C:\\Users\\cemzuza\\Desktop\\llm-classification-finetuning\")\n",
    "TRAIN_PATH = DATA_DIR / \"train.csv\"\n",
    "TEST_PATH = DATA_DIR / \"test.csv\"\n",
    "SAMPLE_SUB_PATH = DATA_DIR / \"sample_submission.csv\"\n",
    "\n",
    "for p in [TRAIN_PATH, TEST_PATH, SAMPLE_SUB_PATH]:\n",
    "    print(p, \"==>\", p.exists())\n",
    "\n",
    "train = pd.read_csv(TRAIN_PATH)\n",
    "test  = pd.read_csv(TEST_PATH)\n",
    "sample = pd.read_csv(SAMPLE_SUB_PATH)\n",
    "\n",
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Test shape :\", test.shape)\n",
    "print(\"\\nKolumny train:\", list(train.columns))\n",
    "print(\"Kolumny test :\", list(test.columns))\n",
    "\n",
    "train.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdcdc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rozkład klas (proporcje):\n",
      "A      0.349079\n",
      "B      0.341911\n",
      "TIE    0.309011\n",
      "Name: ratio, dtype: float64\n",
      "\n",
      "Przykładowe etykiety: ['A', 'B', 'TIE', 'A', 'B', 'B', 'A', 'B', 'B', 'B']\n",
      "Przykładowe cechy liczbowe:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>len_char_a</th>\n",
       "      <th>len_word_a</th>\n",
       "      <th>n_lines_a</th>\n",
       "      <th>n_code_a</th>\n",
       "      <th>n_urls_a</th>\n",
       "      <th>n_q_a</th>\n",
       "      <th>n_excl_a</th>\n",
       "      <th>n_quotes_a</th>\n",
       "      <th>len_char_b</th>\n",
       "      <th>len_word_b</th>\n",
       "      <th>...</th>\n",
       "      <th>n_excl_b</th>\n",
       "      <th>n_quotes_b</th>\n",
       "      <th>diff_len_char</th>\n",
       "      <th>diff_len_word</th>\n",
       "      <th>diff_n_lines</th>\n",
       "      <th>diff_n_code</th>\n",
       "      <th>diff_n_urls</th>\n",
       "      <th>diff_n_q</th>\n",
       "      <th>diff_n_excl</th>\n",
       "      <th>diff_n_quotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4538</td>\n",
       "      <td>656</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>1206</td>\n",
       "      <td>204</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3332</td>\n",
       "      <td>452</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3114</td>\n",
       "      <td>531</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3649</td>\n",
       "      <td>571</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>-535</td>\n",
       "      <td>-40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>921</td>\n",
       "      <td>138</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>1835</td>\n",
       "      <td>280</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>-914</td>\n",
       "      <td>-142</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   len_char_a  len_word_a  n_lines_a  n_code_a  n_urls_a  n_q_a  n_excl_a  \\\n",
       "0        4538         656          1         0         0      1         5   \n",
       "1        3114         531          1         0         0      0         0   \n",
       "2         921         138          1         2         0      0         2   \n",
       "\n",
       "   n_quotes_a  len_char_b  len_word_b  ...  n_excl_b  n_quotes_b  \\\n",
       "0          16        1206         204  ...         2           4   \n",
       "1           6        3649         571  ...         0           6   \n",
       "2          20        1835         280  ...         0          14   \n",
       "\n",
       "   diff_len_char  diff_len_word  diff_n_lines  diff_n_code  diff_n_urls  \\\n",
       "0           3332            452             0            0            0   \n",
       "1           -535            -40             0            0            0   \n",
       "2           -914           -142             0           -2            0   \n",
       "\n",
       "   diff_n_q  diff_n_excl  diff_n_quotes  \n",
       "0         1            3             12  \n",
       "1         0            0              0  \n",
       "2         0            2              6  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "target_cols = [\"winner_model_a\", \"winner_model_b\", \"winner_tie\"]\n",
    "label_map = {\"winner_model_a\": \"A\", \"winner_model_b\": \"B\", \"winner_tie\": \"TIE\"}\n",
    "y = train[target_cols].idxmax(axis=1).map(label_map)\n",
    "\n",
    "print(\"Rozkład klas (proporcje):\")\n",
    "print(y.value_counts(normalize=True).rename(\"ratio\"))\n",
    "print()\n",
    "print(\"Przykładowe etykiety:\", y[:10].tolist())\n",
    "\n",
    "def simple_numeric_feats(df):\n",
    "    out = {}\n",
    "    for side in [\"a\", \"b\"]:\n",
    "        s = df[f\"response_{side}\"].fillna(\"\")\n",
    "        out[f\"len_char_{side}\"] = s.str.len()  \n",
    "        out[f\"len_word_{side}\"] = s.str.split().str.len()  \n",
    "        out[f\"n_lines_{side}\"]  = s.str.count(\"\\n\") + 1  \n",
    "        out[f\"n_code_{side}\"]   = s.str.count(\"```\") \n",
    "        out[f\"n_urls_{side}\"]   = s.str.count(r\"http[s]?://\")  \n",
    "        out[f\"n_q_{side}\"]      = s.str.count(r\"\\?\")  \n",
    "        out[f\"n_excl_{side}\"]   = s.str.count(r\"!\")   \n",
    "        out[f\"n_quotes_{side}\"] = s.str.count(r'\"')  \n",
    "    num = pd.DataFrame(out).fillna(0)\n",
    "    for base in [\"len_char\",\"len_word\",\"n_lines\",\"n_code\",\"n_urls\",\"n_q\",\"n_excl\",\"n_quotes\"]:\n",
    "        num[f\"diff_{base}\"] = num[f\"{base}_a\"] - num[f\"{base}_b\"]\n",
    "    return num\n",
    "num_train = simple_numeric_feats(train)\n",
    "num_test  = simple_numeric_feats(test)\n",
    "print(\"Przykładowe cechy liczbowe:\")\n",
    "num_train.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd4342b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF train shape: (57477, 60000)\n",
      "TF-IDF test  shape: (3, 60000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "\n",
    "tfidf_word = TfidfVectorizer(\n",
    "    strip_accents=\"unicode\",\n",
    "    lowercase=True,\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=10_000,\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "tfidf_char = TfidfVectorizer(\n",
    "    analyzer=\"char\",\n",
    "    ngram_range=(3, 5),\n",
    "    max_features=10_000,\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "def tfidf_fit_transform(col_train, col_test):\n",
    "    \"\"\"\n",
    "    Dla jednej kolumny tekstowej:\n",
    "    - dopasuj TF-IDF na train,\n",
    "    - przetransformuj train i test,\n",
    "    - złącz WORD + CHAR w jeden blok cech (hstack).\n",
    "    \"\"\"\n",
    "    Xw_tr = tfidf_word.fit_transform(col_train)\n",
    "    Xw_te = tfidf_word.transform(col_test)\n",
    "    Xc_tr = tfidf_char.fit_transform(col_train)\n",
    "    Xc_te = tfidf_char.transform(col_test)\n",
    "    X_tr = sparse.hstack([Xw_tr, Xc_tr], format=\"csr\")\n",
    "    X_te = sparse.hstack([Xw_te, Xc_te], format=\"csr\")\n",
    "    return X_tr, X_te\n",
    "\n",
    "text_cols = [\"prompt\", \"response_a\", \"response_b\"]\n",
    "X_blocks_tr, X_blocks_te = [], []\n",
    "\n",
    "for c in text_cols:\n",
    "    col_tr = train[c].fillna(\"\") \n",
    "    col_te = test[c].fillna(\"\")\n",
    "    Xtr, Xte = tfidf_fit_transform(col_tr, col_te)\n",
    "    X_blocks_tr.append(Xtr)\n",
    "    X_blocks_te.append(Xte)\n",
    "\n",
    "X_text_tr = sparse.hstack(X_blocks_tr, format=\"csr\")\n",
    "X_text_te = sparse.hstack(X_blocks_te, format=\"csr\")\n",
    "\n",
    "print(\"TF-IDF train shape:\", X_text_tr.shape)\n",
    "print(\"TF-IDF test  shape:\", X_text_te.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831e96d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL train shape: (57477, 60024) | FULL test shape: (3, 60024)\n",
      "TF-IDF feats: 60000 | numeric feats: 24 | total: 60024\n",
      "Klasy (kody): [0 1 2] ↔ ['A', 'B', 'TIE']\n"
     ]
    }
   ],
   "source": [
    "from scipy import sparse\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "assert 'X_text_tr' in globals() and 'X_text_te' in globals(), \"Najpierw uruchom Krok 3 (TF-IDF).\"\n",
    "assert 'num_train' in globals() and 'num_test' in globals(), \"Brakuje cech liczbowych (Krok 2).\"\n",
    "assert 'y' in globals(), \"Brakuje y (etykiet) z Kroku 2.\"\n",
    "\n",
    "if not sparse.issparse(X_text_tr): X_text_tr = sparse.csr_matrix(X_text_tr)\n",
    "if not sparse.issparse(X_text_te): X_text_te = sparse.csr_matrix(X_text_te)\n",
    "\n",
    "scaler = StandardScaler(with_mean=False) \n",
    "X_num_tr = scaler.fit_transform(num_train.values.astype(float))\n",
    "X_num_te = scaler.transform(num_test.values.astype(float))\n",
    "\n",
    "X_tr_all = sparse.hstack([X_text_tr, X_num_tr], format=\"csr\")\n",
    "X_te_all = sparse.hstack([X_text_te, X_num_te], format=\"csr\")\n",
    "\n",
    "print(\"FULL train shape:\", X_tr_all.shape, \"| FULL test shape:\", X_te_all.shape)\n",
    "print(\"TF-IDF feats:\", X_text_tr.shape[1], \"| numeric feats:\", X_num_tr.shape[1], \"| total:\", X_tr_all.shape[1])\n",
    "\n",
    "classes = np.array([\"A\",\"B\",\"TIE\"])\n",
    "y_idx = pd.Categorical(y, categories=classes).codes\n",
    "print(\"Klasy (kody):\", np.unique(y_idx), \"↔\", classes.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c0c84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start 3-fold walidacji (solver=lbfgs, C=2.0, max_iter=800)...\n",
      "Fold 1: log loss = 1.291410\n",
      "Fold 2: log loss = 1.291325\n",
      "Fold 3: log loss = 1.315543\n",
      "\n",
      "Fold scores: ['1.291410', '1.291325', '1.315543']\n",
      "OOF log loss: 1.299426\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "assert 'X_tr_all' in globals(), \"Brakuje X_tr_all (uruchom Krok 4: łączenie TF-IDF + cechy liczbowe).\"\n",
    "assert 'y' in globals(), \"Brakuje y (uruchom Krok 2: etykiety A/B/TIE).\"\n",
    "\n",
    "classes = np.array([\"A\",\"B\",\"TIE\"])\n",
    "y_idx = pd.Categorical(y, categories=classes).codes\n",
    "\n",
    "N_FOLDS  = 3          \n",
    "SOLVER   = \"lbfgs\"    \n",
    "C_VALUE  = 2.0        \n",
    "MAX_ITER = 800        \n",
    "USE_BALANCED = False\n",
    "# ---------------------------------------------------\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "oof_proba  = np.zeros((X_tr_all.shape[0], 3), dtype=float)\n",
    "fold_scores = []\n",
    "\n",
    "print(f\"Start {N_FOLDS}-fold walidacji (solver={SOLVER}, C={C_VALUE}, max_iter={MAX_ITER})...\")\n",
    "for fold, (tr_idx, va_idx) in enumerate(skf.split(X_tr_all, y_idx), 1):\n",
    "    X_tr, X_va = X_tr_all[tr_idx], X_tr_all[va_idx]\n",
    "    y_tr, y_va = y_idx[tr_idx], y_idx[va_idx]\n",
    "\n",
    "    clf = LogisticRegression(\n",
    "        solver=SOLVER,\n",
    "        max_iter=MAX_ITER,\n",
    "        C=C_VALUE,\n",
    "        random_state=fold,\n",
    "        class_weight=\"balanced\" if USE_BALANCED else None\n",
    "    )\n",
    "\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    pr = clf.predict_proba(X_va)\n",
    "    ll = log_loss(y_va, pr, labels=[0,1,2])\n",
    "\n",
    "    oof_proba[va_idx] = pr\n",
    "    fold_scores.append(ll)\n",
    "    print(f\"Fold {fold}: log loss = {ll:.6f}\")\n",
    "\n",
    "oof_ll = log_loss(y_idx, oof_proba, labels=[0,1,2])\n",
    "print(\"\\nFold scores:\", [f\"{s:.6f}\" for s in fold_scores])\n",
    "print(f\"OOF log loss: {oof_ll:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873e7b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start treningu na CAŁYM train...\n",
      "Trening zakończony.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cemzuza\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\linear_model\\_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "assert 'X_tr_all' in globals(), \"Brakuje X_tr_all (uruchom Krok 4).\"\n",
    "assert 'y' in globals(), \"Brakuje y (uruchom Krok 2: etykiety A/B/TIE).\"\n",
    "\n",
    "classes = np.array([\"A\", \"B\", \"TIE\"])\n",
    "y_idx = pd.Categorical(y, categories=classes).codes\n",
    "\n",
    "final_clf = LogisticRegression(\n",
    "    solver=\"lbfgs\",   \n",
    "    max_iter=800,     \n",
    "    C=2.0,           \n",
    "    random_state=123\n",
    ")\n",
    "\n",
    "print(\"Start treningu na CAŁYM train...\")\n",
    "final_clf.fit(X_tr_all, y_idx)\n",
    "print(\"Trening zakończony.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd9f402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Średnia suma wiersza (powinno być ≈ 1.0): 1.0\n",
      "NaN w submission?: {'id': False, 'winner_model_a': False, 'winner_model_b': False, 'winner_tie': False}\n",
      "Zapisano: submission.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>winner_model_a</th>\n",
       "      <th>winner_model_b</th>\n",
       "      <th>winner_tie</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>136060</td>\n",
       "      <td>0.081277</td>\n",
       "      <td>0.327808</td>\n",
       "      <td>0.590916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>211333</td>\n",
       "      <td>0.817818</td>\n",
       "      <td>0.121692</td>\n",
       "      <td>0.060490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1233961</td>\n",
       "      <td>0.509131</td>\n",
       "      <td>0.257815</td>\n",
       "      <td>0.233054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  winner_model_a  winner_model_b  winner_tie\n",
       "0   136060        0.081277        0.327808    0.590916\n",
       "1   211333        0.817818        0.121692    0.060490\n",
       "2  1233961        0.509131        0.257815    0.233054"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "assert 'X_te_all' in globals(), \"Brakuje X_te_all (uruchom Krok 4).\"\n",
    "assert 'test' in globals(), \"Brakuje DataFrame 'test' (Krok 1).\"\n",
    "assert 'final_clf' in globals(), \"Brakuje final_clf (uruchom Krok 6A).\"\n",
    "\n",
    "classes = np.array([\"A\", \"B\", \"TIE\"])\n",
    "test_proba = final_clf.predict_proba(X_te_all)\n",
    "\n",
    "sub = pd.DataFrame({\n",
    "    \"id\": test[\"id\"].values,\n",
    "    \"winner_model_a\": test_proba[:, classes.tolist().index(\"A\")],\n",
    "    \"winner_model_b\": test_proba[:, classes.tolist().index(\"B\")],\n",
    "    \"winner_tie\":    test_proba[:, classes.tolist().index(\"TIE\")],\n",
    "})\n",
    "\n",
    "row_sums = sub[[\"winner_model_a\",\"winner_model_b\",\"winner_tie\"]].sum(axis=1)\n",
    "print(\"Średnia suma wiersza (powinno być ≈ 1.0):\", float(row_sums.mean()))\n",
    "print(\"NaN w submission?:\", sub.isna().any().to_dict())\n",
    "\n",
    "out_path = \"submission.csv\"\n",
    "sub.to_csv(out_path, index=False)\n",
    "print(\"Zapisano:\", out_path)\n",
    "sub.head()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
